{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM\n",
    "def reshape_data_for_lstm(x_train, x_test_scaled, x_val_scaled):\n",
    "    x_train_array = x_train.values\n",
    "    x_train_reshaped = np.expand_dims(x_train_array, axis=1)\n",
    "\n",
    "    x_test_array = x_test_scaled.values\n",
    "    x_test_reshaped = np.expand_dims(x_test_array, axis=1)\n",
    "\n",
    "    x_val_array = x_val_scaled.values\n",
    "    x_val_reshaped = np.expand_dims(x_val_array, axis=1)\n",
    "\n",
    "    input_shape = (1, x_train_reshaped.shape[2]) #for LSTM\n",
    "    return x_train_reshaped, x_test_reshaped, x_val_reshaped, input_shape\n",
    "\n",
    "\n",
    "\n",
    "###cnn\n",
    "def reshape_data_for_cnn(x_train, x_test_scaled, x_val_scaled):\n",
    "    x_train_array = x_train.values\n",
    "    x_train_reshaped = np.expand_dims(x_train_array, axis=-1)\n",
    "\n",
    "    x_test_array = x_test_scaled.values\n",
    "    x_test_reshaped = np.expand_dims(x_test_array, axis=-1)\n",
    "\n",
    "    x_val_array = x_val_scaled.values\n",
    "    x_val_reshaped = np.expand_dims(x_val_array, axis=-1)\n",
    "\n",
    "    input_shape = (x_train_reshaped.shape[1],1) #cnn\n",
    "    return x_train_reshaped, x_test_reshaped, x_val_reshaped, input_shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predDataForModelWithDaynight(mode, data_type = 'validation'):\n",
    "    data = pd.read_csv('./merged_data.csv')\n",
    "\n",
    "    data['daynight'] = data['daynight'].replace('D', 1)\n",
    "    data['daynight'] = data['daynight'].replace('N', 0)\n",
    "    target = data['type']\n",
    "\n",
    "    if mode == 'daynight':\n",
    "        dropped_data = data.drop(['longitude','latitude','acq_date','acq_time','satellite','instrument','type','confidence','version','precipitation_sum','frp'], axis=1)#,'daynight'\n",
    "    else:\n",
    "        dropped_data = data.drop(['longitude','latitude','acq_date','acq_time','satellite','instrument','type','daynight','confidence','version','precipitation_sum','frp','daynight'], axis=1)\n",
    "\n",
    "    target.replace({0: 1, 1: 0, 2: 0,3:0},inplace=True)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dropped_data,target, test_size=0.2, random_state=42,stratify=target)\n",
    "    x_train,x_val,y_train, y_val = train_test_split(x_train,y_train, test_size=0.2, random_state=42,stratify=y_train)\n",
    "\n",
    "    # Load the saved scalers\n",
    "    scalers = {}\n",
    "    for column in x_train.columns:\n",
    "\n",
    "        if column == 'daynight':\n",
    "            continue\n",
    "        scaler = joblib.load(f\"{column}_scaler.pkl\")\n",
    "        scalers[column] = scaler\n",
    "\n",
    "    # Transform the validation and test features using the loaded scalers\n",
    "    x_val_scaled = x_val.copy()\n",
    "    x_train_scaled = x_train.copy()\n",
    "    x_test_scaled = x_test.copy()\n",
    "    for column, scaler in scalers.items():\n",
    "        x_train_scaled[[column]] = scaler.transform(x_train[[column]])\n",
    "        x_val_scaled[[column]] = scaler.transform(x_val[[column]])\n",
    "        x_test_scaled[[column]] = scaler.transform(x_test[[column]])\n",
    "    \n",
    "\n",
    "\n",
    "    x_train_reshaped, x_test_reshaped, x_val_reshaped, input_shape = reshape_data_for_cnn(x_train_scaled, x_test_scaled, x_val_scaled)\n",
    "    x_train_reshaped_lstm, x_test_reshaped_lstm, x_val_reshaped_lstm, input_shape = reshape_data_for_lstm(x_train_scaled, x_test_scaled, x_val_scaled)\n",
    "\n",
    "    if data_type=='training':\n",
    "        return x_train_reshaped, x_train_reshaped_lstm, y_train, x_test_reshaped, x_test_reshaped_lstm, y_test\n",
    "    \n",
    "\n",
    "    return x_val_reshaped, x_val_reshaped_lstm, y_val\n",
    "\n",
    "x_val_reshaped_daynight, x_val_reshaped_lstm_daynight, y_val = predDataForModelWithDaynight(mode='daynight')\n",
    "x_val_reshaped, x_val_reshaped_lstm, y_val = predDataForModelWithDaynight(mode='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn1 = load_model('models/cnn_1rst_88acc.h5')\n",
    "model_cnn2 = load_model('models/cnn_daynight_89acc.h5')\n",
    "model_lstm1 = load_model('models/lstm_model_89acc.h5')\n",
    "model_lstm2 = load_model('models/lstm_daynight_90acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict for cnn and plot roc\n",
    "def create_roc_curve(model, data,title):\n",
    "    if title.endswith('with daynight'):\n",
    "        y_pred = model.predict(data.astype('float32')).ravel()\n",
    "    else: \n",
    "        y_pred = model.predict(data).ravel()\n",
    "    # Compute ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic for {title}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = create_roc_curve(model_cnn1, x_val_reshaped,'CNN w/o daynight')\n",
    "a2 = create_roc_curve(model_cnn2, x_val_reshaped_daynight,'CNN with daynight')\n",
    "a3 =create_roc_curve(model_lstm1, x_val_reshaped_lstm,'LSTM w/o daynight')\n",
    "a4 = create_roc_curve(model_lstm2, x_val_reshaped_lstm_daynight,'LSTM with daynight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrices for each model create a function\n",
    "def create_confusion_matrix(model, data,title):\n",
    "    if title.endswith('with daynight'):\n",
    "        y_pred = model.predict(data.astype('float32')).ravel()\n",
    "    else: \n",
    "        y_pred = model.predict(data).ravel()\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # map 1 to Fire and 0 to No Fire\n",
    "    #cm = confusion_matrix(y_val, y_pred)\n",
    "    cm = pd.DataFrame(cm, index=['No Fire', 'Fire'], columns=['No Fire', 'Fire'])\n",
    "\n",
    "    sns.heatmap(cm, annot=True, cmap='OrRd', fmt='g', annot_kws={\"size\": 12},cbar=False)\n",
    "    plt.xlabel('Predicted Classes')\n",
    "    plt.ylabel('Actual Classes')\n",
    "    plt.title('Confusion Matrix for ' + title)\n",
    "    plt.show()\n",
    "\n",
    "b1 = create_confusion_matrix(model_cnn1, x_val_reshaped,'CNN w/o daynight')\n",
    "b2 = create_confusion_matrix(model_cnn2, x_val_reshaped_daynight,'CNN with daynight')\n",
    "b3 = create_confusion_matrix(model_lstm1, x_val_reshaped_lstm,'LSTM w/o daynight')\n",
    "b4 = create_confusion_matrix(model_lstm2, x_val_reshaped_lstm_daynight,'LSTM with daynight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create classification report for each model create a function\n",
    "def create_classification_report(model, data,title):\n",
    "    if title.endswith('with daynight'):\n",
    "        y_pred = model.predict(data.astype('float32')).ravel()\n",
    "    else: \n",
    "        y_pred = model.predict(data).ravel()\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "print('classification_report for CNN w/o daynight')\n",
    "c1 = create_classification_report(model_cnn1, x_val_reshaped,'CNN w/o daynight')\n",
    "print('classification_report for CNN with daynight')\n",
    "c2 = create_classification_report(model_cnn2, x_val_reshaped_daynight,'CNN with daynight')\n",
    "print('classification_report for LSTM w/o daynight')\n",
    "c3 = create_classification_report(model_lstm1, x_val_reshaped_lstm,'LSTM w/o daynight')\n",
    "print('classification_report for LSTM with daynight')\n",
    "c4 = create_classification_report(model_lstm2, x_val_reshaped_lstm_daynight,'LSTM with daynight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn1 = model_cnn1.predict(x_val_reshaped)\n",
    "y_pred_cnn1 = np.where(y_pred_cnn1 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_cnn2 = model_cnn2.predict(x_val_reshaped_daynight.astype('float32'))\n",
    "y_pred_cnn2 = np.where(y_pred_cnn2 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_lstm1 = model_lstm1.predict(x_val_reshaped_lstm)\n",
    "y_pred_lstm1 = np.where(y_pred_lstm1 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_lstm2 = model_lstm2.predict(x_val_reshaped_lstm_daynight.astype('float32'))  \n",
    "y_pred_lstm2 = np.where(y_pred_lstm2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def vote(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num\n",
    "\n",
    "y_ens_pred = []\n",
    "count = []\n",
    "for i in range(len(y_pred_cnn1)):\n",
    "    count.append(y_pred_cnn1[i])\n",
    "    #count.append(y_pred_cnn2[i])\n",
    "    count.append(y_pred_lstm1[i])\n",
    "    count.append(y_pred_lstm2[i])\n",
    "    y_ens_pred.append(vote(count))\n",
    "    count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ens_pred = [x.astype('int') for x in y_ens_pred]\n",
    "y_ens_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "def vote(List):\n",
    "    if not List:\n",
    "        return None\n",
    "    counter = Counter(List)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "def average_vote(List):\n",
    "    if not List:\n",
    "        return None\n",
    "    return np.mean(List)\n",
    "\n",
    "y_ens_pred_average = []\n",
    "y_ens_pred_majority = []\n",
    "for i in range(len(y_pred_cnn1)):\n",
    "    # Ensure that each prediction is a scalar value\n",
    "    pred_cnn1 = y_pred_cnn1[i] if not isinstance(y_pred_cnn1[i], np.ndarray) else y_pred_cnn1[i].item()\n",
    "    pred_lstm1 = y_pred_lstm1[i] if not isinstance(y_pred_lstm1[i], np.ndarray) else y_pred_lstm1[i].item()\n",
    "    pred_lstm2 = y_pred_lstm2[i] if not isinstance(y_pred_lstm2[i], np.ndarray) else y_pred_lstm2[i].item()\n",
    "    pred_cnn2 = y_pred_cnn2[i] if not isinstance(y_pred_cnn2[i], np.ndarray) else y_pred_cnn2[i].item()\n",
    "    \n",
    "    average_count = [\n",
    "            pred_cnn1,\n",
    "            pred_cnn2, \n",
    "            pred_lstm1, \n",
    "            pred_lstm2\n",
    "        ]\n",
    "\n",
    "    \n",
    "    majority_count = [\n",
    "            pred_cnn1,\n",
    "            #pred_cnn2, \n",
    "            pred_lstm1, \n",
    "            pred_lstm2\n",
    "        ]\n",
    "\n",
    "    \n",
    "    y_ens_pred_majority.append(vote(majority_count))\n",
    "    y_ens_pred_average.append(average_vote(average_count))\n",
    "\n",
    "# Ensure y_ens_pred is of the same type as y_val\n",
    "y_ens_pred_average = [int(x) for x in y_ens_pred_average]\n",
    "y_ens_pred_majority = [int(x) for x in y_ens_pred_majority]\n",
    "\n",
    "\n",
    "print('classification_report for Ensemble with average vote')\n",
    "print(classification_report(y_val, y_ens_pred_average))\n",
    "\n",
    "print('classification_report for Ensemble with majority vote')\n",
    "print(classification_report(y_val, y_ens_pred_majority))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrices for ensemble models\n",
    "def create_confusion_matrix_ensemble(y_pred,title):\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # map 1 to Fire and 0 to No Fire\n",
    "    #cm = confusion_matrix(y_val, y_pred)\n",
    "    cm = pd.DataFrame(cm, index=['No Fire', 'Fire'], columns=['No Fire', 'Fire'])\n",
    "\n",
    "    sns.heatmap(cm, annot=True, cmap='OrRd', fmt='g', annot_kws={\"size\": 12},cbar=False)\n",
    "    plt.xlabel('Predicted Classes')\n",
    "    plt.ylabel('Actual Classes')\n",
    "    plt.title('Confusion Matrix for ' + title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "d1 = create_confusion_matrix_ensemble(y_ens_pred_average,'Ensemble with average vote')\n",
    "d2 = create_confusion_matrix_ensemble(y_ens_pred_majority,'Ensemble with majority vote')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cnn1.predict(x_test_reshaped)\n",
    "\n",
    "# y_pred_test_cnn1 = model_cnn1.predict(x_test_reshaped)\n",
    "# y_pred_test_cnn1 = np.where(y_pred_test_cnn1 > 0.5, 1, 0)\n",
    "\n",
    "# y_pred_test_cnn2 = model_cnn2.predict(x_test_reshaped_daynight.astype('float32'))\n",
    "# y_pred_test_cnn2 = np.where(y_pred_test_cnn2 > 0.5, 1, 0)\n",
    "\n",
    "# y_pred_test_lstm1 = model_lstm1.predict(x_test_reshaped_lstm).ravel()\n",
    "# y_pred_test_lstm1 = np.where(y_pred_test_lstm1 > 0.5, 1, 0)\n",
    "\n",
    "# y_pred_test_lstm2 = model_lstm2.predict(x_test_reshaped_lstm_daynight.astype('float32')).ravel()\n",
    "# y_pred_test_lstm2 = np.where(y_pred_test_lstm2 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_train_cnn1 = model_cnn1.predict(x_train_reshaped)\n",
    "y_pred_train_cnn1 = np.where(y_pred_train_cnn1 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_train_cnn2 = model_cnn2.predict(x_train_reshaped_daynight.astype('float32'))\n",
    "y_pred_train_cnn2 = np.where(y_pred_train_cnn2 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_train_lstm1 = model_lstm1.predict(x_train_reshaped_lstm).ravel()\n",
    "y_pred_train_lstm1 = np.where(y_pred_train_lstm1 > 0.5, 1, 0)\n",
    "\n",
    "y_pred_train_lstm2 = model_lstm2.predict(x_train_reshaped_lstm_daynight.astype('float32')).ravel()\n",
    "y_pred_train_lstm2 = np.where(y_pred_train_lstm2 > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_train_cnn1))\n",
    "print(classification_report(y_train, y_pred_train_cnn2))\n",
    "print(classification_report(y_train, y_pred_train_lstm1))\n",
    "print(classification_report(y_train, y_pred_train_lstm2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report for test data not the ensebmle\n",
    "print(classification_report(y_pred_test_cnn1, y_test))\n",
    "print(classification_report(y_pred_test_cnn2, y_test))\n",
    "print(classification_report(y_pred_test_lstm1, y_test))\n",
    "print(classification_report(y_pred_test_lstm2, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshaped_daynight, x_train_reshaped_lstm_daynight, y_train, x_test_reshaped_daynight, x_test_reshaped_lstm_daynight, y_test = predDataForModelWithDaynight(mode='daynight',data_type='training')\n",
    "x_train_reshaped, x_train_reshaped_lstm, y_train, x_test_reshaped, x_test_reshaped_lstm, y_test = predDataForModelWithDaynight(mode='',data_type='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def create_model_training_loss_graph(model, training_data,test_data, title):\n",
    "     # keep model architecture  get rid of weights retrain model\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    # Step 2: Create a new model from the saved architecture\n",
    "    new_model = tf.keras.models.model_from_json(model_json)\n",
    "\n",
    "    # Step 3: Compile the model\n",
    "    new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    "    )\n",
    "    # Step 4: Train the model\n",
    "    history = new_model.fit(training_data, y_train, epochs=30, batch_size=32,validation_data=(test_data, y_test),callbacks=[early_stopping])\n",
    "\n",
    "    # Step 5: Plot the training and validation loss\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Training and Validation Loss for {title}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "e1 = create_model_training_loss_graph(model_cnn1, x_train_reshaped,x_test_reshaped,'CNN w/o daynight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = create_model_training_loss_graph(model_cnn2, x_train_reshaped_daynight.astype('float32'),x_test_reshaped_daynight.astype('float32'),'CNN with daynight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = create_model_training_loss_graph(model_lstm1, x_train_reshaped_lstm,x_test_reshaped_lstm,'LSTM w/o daynight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
